{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP CW - Michelle Lo, Hetty Symes, Evelyn Nutton\n",
    "\n",
    "RoBERTa base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import pipeline, RobertaModel, AutoTokenizer, AutoModelForSequenceClassification, AdamW, DataCollatorWithPadding, get_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "import nlpaug.augmenter.word as naw\n",
    "import sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /homes/hys21/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /homes/hys21/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download content needed for text augmentation\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"White House press secretary Sean Spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\"\"\" Just like we received migrants fleeing El ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   par_id      art_id    keyword country  \\\n",
       "0       1  @@24942188   hopeless      ph   \n",
       "1       2  @@21968160    migrant      gh   \n",
       "2       3  @@16584954  immigrant      ie   \n",
       "3       4   @@7811231   disabled      nz   \n",
       "4       5   @@1494111    refugee      ca   \n",
       "\n",
       "                                                text  label  orig_label  \n",
       "0  We 're living in times of absolute insanity , ...      0           0  \n",
       "1  In Libya today , there are countless number of...      0           0  \n",
       "2  \"White House press secretary Sean Spicer said ...      0           0  \n",
       "3  Council customers only signs would be displaye...      0           0  \n",
       "4  \"\"\" Just like we received migrants fleeing El ...      0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df = pd.read_csv(\"train_dev_data/train_set.csv\")\n",
    "test_df = pd.read_csv(\"train_dev_data/dev_set.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, truncation=True, do_lower_case=True)\n",
    "pretrained_model = RobertaModel.from_pretrained(checkpoint, num_labels=2)\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the data\n",
    "class PCLData(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, augment=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.text = self.data.text\n",
    "        self.targets = self.data.label\n",
    "        self.max_len = max_len\n",
    "        self.augment = augment\n",
    "        self.synonym_aug = naw.SynonymAug(aug_src='wordnet', aug_p=0.3)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        if self.augment:\n",
    "            text = self.synonym_aug.augment(text)[0]\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (8375, 7)\n",
      "TEST Dataset: (2094, 7)\n",
      "{'ids': tensor([[    0,   113,   229,  ...,     1,     1,     1],\n",
      "        [    0,   113,  8948,  ...,     1,     1,     1],\n",
      "        [    0,  1185,    64,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   113,    22,  ...,     1,     1,     1],\n",
      "        [    0,  2409,   101,  ...,     1,     1,     1],\n",
      "        [    0, 41339,    16,  ...,     1,     1,     1]]), 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'targets': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])}\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "train_dataset = PCLData(train_df, tokenizer, MAX_LEN, augment=True)\n",
    "test_dataset = PCLData(test_df, tokenizer, MAX_LEN, augment=False)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 4,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(train_dataset, **train_params)\n",
    "testing_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = pretrained_model\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "\n",
    "\n",
    "class SelfAdjDiceLoss(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    Creates a criterion that optimizes a multi-class Self-adjusting Dice Loss\n",
    "    (\"Dice Loss for Data-imbalanced NLP Tasks\" paper)\n",
    "\n",
    "    Args:\n",
    "        alpha (float): a factor to push down the weight of easy examples\n",
    "        gamma (float): a factor added to both the nominator and the denominator for smoothing purposes\n",
    "        reduction (string): Specifies the reduction to apply to the output:\n",
    "            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
    "            ``'mean'``: the sum of the output will be divided by the number of\n",
    "            elements in the output, ``'sum'``: the output will be summed.\n",
    "\n",
    "    Shape:\n",
    "        - logits: `(N, C)` where `N` is the batch size and `C` is the number of classes.\n",
    "        - targets: `(N)` where each value is in [0, C - 1]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha: float = 1.0, gamma: float = 1.0, reduction: str = \"mean\") -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        probs = torch.gather(probs, dim=1, index=targets.unsqueeze(1))\n",
    "\n",
    "        probs_with_factor = ((1 - probs) ** self.alpha) * probs\n",
    "        loss = 1 - (2 * probs_with_factor + self.gamma) / (probs_with_factor + 1 + self.gamma)\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        elif self.reduction == \"none\" or self.reduction is None:\n",
    "            return loss\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Reduction `{self.reduction}` is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the loss function and optimizer\n",
    "criterion = SelfAdjDiceLoss()\n",
    "# loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0; n_correct = 0; steps = 0; seen = 0\n",
    "    model.train()\n",
    "    for i,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        preds = model(ids, mask, token_type_ids)\n",
    "        loss = criterion(preds, targets)\n",
    "        tr_loss += loss.item()\n",
    "        _, pred_labels = torch.max(preds.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(pred_labels, targets)\n",
    "\n",
    "        steps += 1\n",
    "        seen+=targets.size(0)\n",
    "        \n",
    "        if i%5000==0:\n",
    "            curr_loss = tr_loss/steps\n",
    "            curr_acc = (n_correct*100)/seen \n",
    "            print(f\"Training Loss per 5000 steps: {curr_loss}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {curr_acc}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Total Accuracy for Epoch {epoch}: {(n_correct*100)/seen}')\n",
    "    epoch_loss = tr_loss/steps\n",
    "    epoch_accu = (n_correct*100)/seen\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2690: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m tr_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m; n_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m; steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m; seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m, in \u001b[0;36mPCLData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n\u001b[1;32m     19\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynonym_aug\u001b[38;5;241m.\u001b[39maugment(text)\n\u001b[0;32m---> 21\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3063\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3054\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3055\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3056\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3060\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3061\u001b[0m )\n\u001b[0;32m-> 3063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:227\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:613\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    591\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    611\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    612\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 613\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:217\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/hys21/nlp-pcl-cw/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:539\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 539\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    551\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    553\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    563\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [00:45, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data = 89.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; steps=0; seen=0\n",
    "    preds_model = torch.tensor([]).to(device); targets_model = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            preds = model(ids, mask, token_type_ids).squeeze()\n",
    "            \n",
    "            _, pred_labels = torch.max(preds.data, dim=1)\n",
    "            n_correct += calcuate_accuracy(pred_labels, targets)\n",
    "\n",
    "            steps += 1\n",
    "            seen+=targets.size(0)\n",
    "\n",
    "            preds_model = torch.cat((preds_model, pred_labels))\n",
    "            targets_model = torch.cat((targets_model, targets))\n",
    "            \n",
    "    epoch_accu = (n_correct*100)/seen\n",
    "\n",
    "    \n",
    "    \n",
    "    return epoch_accu, preds_model, targets_model\n",
    "\n",
    "acc, preds, targets = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94      1895\n",
      "         1.0       0.48      0.64      0.55       199\n",
      "\n",
      "    accuracy                           0.90      2094\n",
      "   macro avg       0.72      0.78      0.74      2094\n",
      "weighted avg       0.91      0.90      0.91      2094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1755  140]\n",
      " [  72  127]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(targets.cpu().numpy(), preds.cpu().numpy()))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(targets.cpu().numpy(), preds.cpu().numpy())\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
